{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaxxEFguxQwP"
   },
   "source": [
    "# CONVOLUTIONAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utdekY0KxbvB"
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rXPkwvKRxZZw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWNXPsCgzQi2"
   },
   "source": [
    "### PREPROCESSING TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s8MXMKiazaz0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datag=ImageDataGenerator(rescale=1./255,zoom_range=0.2,shear_range=0.2,horizontal_flip=True)\n",
    "train=datag.flow_from_directory('dataset/training_set',batch_size=32,target_size=(64,64),class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLVP2cO2AIFp"
   },
   "source": [
    "### Preprocessing test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9Jw0P6r_AODs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datag=ImageDataGenerator(rescale=1./255)\n",
    "test=datag.flow_from_directory('dataset/test_set',batch_size=32,target_size=(64,64),class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6exLDKBBFHX"
   },
   "source": [
    "BUILDING CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hz77CekaB4Ey"
   },
   "source": [
    "intialse cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hX-pA8qpB7_y"
   },
   "outputs": [],
   "source": [
    "cnn=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZBU-kg8DZlN"
   },
   "source": [
    "CONVOLUTION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CYCgwgoYDe27"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4A3xhvzCGSfC"
   },
   "source": [
    "POOLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4SFTkxLwGYuL"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOjY13IiGz4f"
   },
   "source": [
    "2ND CONVOLUTION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LPUkMS0TG5jh"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHKeMonsH2qB"
   },
   "source": [
    "FLATTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZAJ2wYW2H6RD"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jmp8h5HTIIxQ"
   },
   "source": [
    "FULL CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3GLUiXPdILyE"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBnCc4aVIhxr"
   },
   "source": [
    "OUTPUT LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZCDo3BdkIkn0"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRwwSYElI7qR"
   },
   "source": [
    "#TRAINING CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaZ0LAMfJA21"
   },
   "source": [
    "COMPILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ce_94kRYJEo_"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZZuQhQRJeIz"
   },
   "source": [
    "FIT CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CPIMdunEJhOy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 429s 2s/step - loss: 0.6834 - accuracy: 0.5460 - val_loss: 0.6669 - val_accuracy: 0.5910\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 251s 1s/step - loss: 0.6301 - accuracy: 0.6469 - val_loss: 0.6079 - val_accuracy: 0.6730\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 207s 827ms/step - loss: 0.5744 - accuracy: 0.7049 - val_loss: 0.5388 - val_accuracy: 0.7310\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 201s 802ms/step - loss: 0.5324 - accuracy: 0.7385 - val_loss: 0.5073 - val_accuracy: 0.7565\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 217s 866ms/step - loss: 0.4909 - accuracy: 0.7620 - val_loss: 0.4858 - val_accuracy: 0.7705\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 189s 754ms/step - loss: 0.4668 - accuracy: 0.7791 - val_loss: 0.5030 - val_accuracy: 0.7635\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 228s 913ms/step - loss: 0.4530 - accuracy: 0.7896 - val_loss: 0.4567 - val_accuracy: 0.7845\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 201s 802ms/step - loss: 0.4291 - accuracy: 0.7977 - val_loss: 0.4314 - val_accuracy: 0.7940\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 211s 843ms/step - loss: 0.4051 - accuracy: 0.8106 - val_loss: 0.4413 - val_accuracy: 0.7945\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 202s 807ms/step - loss: 0.3991 - accuracy: 0.8175 - val_loss: 0.4239 - val_accuracy: 0.8085\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 211s 842ms/step - loss: 0.3828 - accuracy: 0.8256 - val_loss: 0.4398 - val_accuracy: 0.7960\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 266s 1s/step - loss: 0.3791 - accuracy: 0.8274 - val_loss: 0.4069 - val_accuracy: 0.8130\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 237s 948ms/step - loss: 0.3510 - accuracy: 0.8447 - val_loss: 0.4158 - val_accuracy: 0.8065\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 217s 868ms/step - loss: 0.3462 - accuracy: 0.8486 - val_loss: 0.4232 - val_accuracy: 0.8155\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 222s 886ms/step - loss: 0.3366 - accuracy: 0.8509 - val_loss: 0.4423 - val_accuracy: 0.8045\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 248s 994ms/step - loss: 0.3129 - accuracy: 0.8655 - val_loss: 0.4159 - val_accuracy: 0.8170\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.3040 - accuracy: 0.8659 - val_loss: 0.4377 - val_accuracy: 0.8220\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 492s 2s/step - loss: 0.2990 - accuracy: 0.8715 - val_loss: 0.4226 - val_accuracy: 0.8220\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 753s 3s/step - loss: 0.2773 - accuracy: 0.8806 - val_loss: 0.4640 - val_accuracy: 0.8165\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 694s 3s/step - loss: 0.2664 - accuracy: 0.8839 - val_loss: 0.4392 - val_accuracy: 0.8210\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 217s 869ms/step - loss: 0.2615 - accuracy: 0.8905 - val_loss: 0.4598 - val_accuracy: 0.8170\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 238s 951ms/step - loss: 0.2475 - accuracy: 0.8980 - val_loss: 0.4718 - val_accuracy: 0.8275\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 265s 1s/step - loss: 0.2378 - accuracy: 0.9031 - val_loss: 0.4839 - val_accuracy: 0.8250\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 199s 795ms/step - loss: 0.2284 - accuracy: 0.9066 - val_loss: 0.5492 - val_accuracy: 0.7990\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 317s 1s/step - loss: 0.2167 - accuracy: 0.9097 - val_loss: 0.4571 - val_accuracy: 0.8305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23041909fc8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=train,validation_data=test,epochs=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-drUjitbJ5Tp"
   },
   "source": [
    "MAKING PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "I2zA6xRgJ8Qj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "imagetest=image.load_img('dataset/single_prediction/cat_or_dog_3.jpg',target_size=(64,64))\n",
    "imagetest=image.img_to_array(imagetest)\n",
    "imagetest=np.expand_dims(imagetest,axis=0)\n",
    "result=cnn.predict(imagetest/255.0)\n",
    "train.class_indices\n",
    "if result[0][0]>0.5:\n",
    "  prediction='dog'\n",
    "else:\n",
    "  prediction='cat'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "SOwEl1GBQ_c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
